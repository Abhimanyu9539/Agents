{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking and tracing\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = \"o3-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Agenti AI\" can refer to a couple of related things, and the exact meaning often depends on the context in which it\\'s used. Here are a few possible interpretations:\\n\\n1. General Concept of AI Agents:\\n\\u2003• In artificial intelligence, an \"agent\" is a system or program that senses its environment, processes information, and takes actions to achieve specific goals—all with some degree of autonomy. When people talk about AI agents, they’re usually referring to software or robots that use AI techniques (like machine learning, natural language processing, or decision-making algorithms) to perform tasks. Examples include chatbots, personal assistants, recommendation systems, and even autonomous vehicles. These agents are designed to interact with users or other software systems without needing explicit, step-by-step instructions from humans for every decision.\\n\\n2. Multi-Agent Systems:\\n\\u2003• In some fields of AI research, especially in multi-agent systems (MAS), multiple autonomous agents work together, sometimes cooperating or competing, to solve complex problems. Here, \"agenti AI\" can sometimes be used (particularly in languages like Italian, where “agenti” is the plural of “agente”) to refer to these systems where numerous AI agents interact in an environment, each contributing to the overall outcome.\\n\\n3. Specific Products or Platforms:\\n\\u2003• Occasionally, you might encounter a company, product, or platform that uses a name similar to \"Agenti AI.\" If the term was encountered in a particular article, advertisement, or discussion, it could be the brand or name of a service that leverages AI agents to deliver its functionality. For example, it might refer to a tool designed to automate customer service, manage tasks, or co-ordinate digital operations using AI-based agents.\\n\\nIf you have a specific context where you saw \"agenti ai\" used—such as in a technical article, a product website, or a discussion about robotics or business automation—providing that context would help narrow down the answer. But in most cases, \"agenti ai\" is generally related to the concept of autonomous, AI-powered agents that are integral to various modern applications in technology and business.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1398, 'prompt_tokens': 12, 'total_tokens': 1410, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 960, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_617f206dd9', 'id': 'chatcmpl-BFP0AJeh2Y1dUjGn0brS880yvVIq2', 'finish_reason': 'stop', 'logprobs': None}, id='run-3467b3f3-904e-4d93-9284-395a5cbb54d6-0', usage_metadata={'input_tokens': 12, 'output_tokens': 1398, 'total_tokens': 1410, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 960}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is agenti ai?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an exper AI Engineer. Provide me answers based on the questions.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are an exper AI Engineer. Provide me answers based on the questions.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform designed to help developers build, monitor, and debug language model applications—especially those built using frameworks like LangChain. Here are some key points about LangSmith:\n",
      "\n",
      "• Purpose and Integration: LangSmith is intended to serve as a centralized dashboard for tracking and analyzing the behavior of your language model workflows. It integrates seamlessly with LangChain, capturing details about chain executions, agent interactions, and callback operations.\n",
      "\n",
      "• Monitoring and Debugging: With LangSmith, you can log the inputs, outputs, and intermediate steps of your language model applications. This detailed logging lets you visualize the flow of data (or “runs”) through your pipelines. The tool is particularly useful for identifying performance bottlenecks, debugging errors, or simply understanding how your application is functioning in production.\n",
      "\n",
      "• Insights and Metrics: By aggregating run data, LangSmith provides developers with insights into which parts of an application may need optimization. It tracks various metrics such as execution times, error rates, and the overall health of operations, which can be crucial for continuous improvement.\n",
      "\n",
      "• Use Cases: Whether you’re building conversational agents, performing complex chain-of-thought reasoning, or creating multi-step LLM applications, LangSmith acts as a valuable companion for:\n",
      "  – Debugging complex chains by tracing each step of execution.\n",
      "  – Understanding how modifications in prompts or chain structures affect output.\n",
      "  – Monitoring application performance and ensuring reliability over time.\n",
      "\n",
      "• Developer Experience: As language model applications grow in complexity, having a robust monitoring and debugging tool becomes essential. LangSmith provides a user-friendly interface tailored for these needs, which means you can quickly zero in on any issues or areas for improvement without needing extensive custom instrumentation.\n",
      "\n",
      "In summary, LangSmith is all about giving developers better control and visibility into their language model applications’ inner workings. It enables a more systematic approach to troubleshooting and performance tuning, making it easier to develop reliable and efficient AI products.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm \n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about langsmith?\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform developed to bring observability, debugging, and improved performance tracking to applications built with large language models (LLMs) and language chains. Here are some key points about Langsmith:\n",
      "\n",
      "• Purpose and Focus – Langsmith is designed to fill the gap in observability for LLM-based applications. As developers build increasingly complex chains, agents, and prompt engineering systems, having a centralized place to track what’s happening “under the hood” becomes crucial. Langsmith gives you a detailed record of the inputs, outputs, intermediate steps, and any errors encountered during execution.\n",
      "\n",
      "• Enhanced Debugging – One of the primary aims of Langsmith is to simplify the debugging process. By logging detailed execution data for each chain run, it becomes easier to pinpoint issues, understand unexpected behavior, and track performance bottlenecks. This helps in fine-tuning prompts and chain logic without having to rely solely on manual inspection or sparse logging.\n",
      "\n",
      "• Performance and Analytics – Beyond error tracking, Langsmith allows developers to analyze the overall performance of LLM applications. Metrics such as response times, success rates, and more granular insights into each step of a chain provide a clearer picture of how the application performs under different conditions. This facilitates more informed optimization and scaling decisions.\n",
      "\n",
      "• Integration with LLM Tooling – Langsmith is often used in conjunction with frameworks like LangChain, which are designed to orchestrate and manage LLM workflows. Its design complements the modularity of these systems by acting as a “black box” where every chain execution is recorded, enabling seamless correlation between code logic and live performance data.\n",
      "\n",
      "• Evolution of LLM Application Development – As the adoption of LLM-powered applications grows, tools like Langsmith are becoming essential. They are part of an ecosystem that not only helps in developing these applications faster but also ensures they perform reliably and can be maintained effectively over time.\n",
      "\n",
      "In summary, Langsmith is all about giving developers the observability tools they need for the next generation of LLM applications—helping to diagnose issues quickly, optimize system performance, and ultimately build more robust, scalable language-based systems.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
